{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MP3_yun.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "SYZkwPO5rdK6",
        "colab_type": "code",
        "outputId": "21ae9ac2-df55-4c0c-b489-078e3e31c2c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        }
      },
      "cell_type": "code",
      "source": [
        "# Plot ad hoc mnist instances\n",
        "from keras.datasets import mnist\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import numpy\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.utils import np_utils\n",
        "import keras\n",
        "import numpy as np\n",
        "from keras.datasets import cifar10\n",
        "from keras.applications.resnet50 import ResNet50\n",
        "from keras.layers import GlobalAveragePooling2D, Dense\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers import Dense\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Model\n",
        "from skimage.transform import resize\n",
        "from IPython import embed\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from urllib.request import urlopen,urlretrieve\n",
        "from PIL import Image\n",
        "from tqdm import tqdm_notebook\n",
        "%matplotlib inline\n",
        "from sklearn.utils import shuffle\n",
        "import cv2\n",
        "\n",
        "from keras.models import load_model\n",
        "from sklearn.datasets import load_files   \n",
        "from keras.utils import np_utils\n",
        "from glob import glob\n",
        "from keras import applications\n",
        "from keras.preprocessing.image import ImageDataGenerator \n",
        "from keras import optimizers\n",
        "from keras.models import Sequential,Model,load_model\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D,GlobalAveragePooling2D\n",
        "from keras.callbacks import TensorBoard,ReduceLROnPlateau,ModelCheckpoint\n",
        "\n",
        "\n",
        "import numpy\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Flatten\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.utils import np_utils\n",
        "from keras import backend as K\n",
        "K.set_image_dim_ordering('th')\n",
        "\n",
        "# load (downloaded if needed) the MNIST dataset\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "# plot 4 images as gray scale\n",
        "plt.subplot(221)\n",
        "plt.imshow(X_train[0], cmap=plt.get_cmap('gray'))\n",
        "plt.subplot(222)\n",
        "plt.imshow(X_train[1], cmap=plt.get_cmap('gray'))\n",
        "plt.subplot(223)\n",
        "plt.imshow(X_train[2], cmap=plt.get_cmap('gray'))\n",
        "plt.subplot(224)\n",
        "plt.imshow(X_train[3], cmap=plt.get_cmap('gray'))\n",
        "# show the plot\n",
        "plt.show()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAToAAAD7CAYAAAD6gVj5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 4 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "f0hiBHBjr-es",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "numpy.random.seed(seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PNVdkf4osHGn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# load data\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fG8ARKc7sHOo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# flatten 28*28 images to a 784 vector for each image\n",
        "num_pixels = X_train.shape[1] * X_train.shape[2]\n",
        "X_train = X_train.reshape(X_train.shape[0], num_pixels).astype('float32')\n",
        "X_test = X_test.reshape(X_test.shape[0], num_pixels).astype('float32')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rNf831fSsHRj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# normalize inputs from 0-255 to 0-1\n",
        "X_train = X_train / 255\n",
        "X_test = X_test / 255\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qj1aon9isHUb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# one hot encode outputs\n",
        "y_train = np_utils.to_categorical(y_train)\n",
        "y_test = np_utils.to_categorical(y_test)\n",
        "num_classes = y_test.shape[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "flDzIfNQsHXC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# define baseline model\n",
        "def baseline_model():\n",
        "\t# create model\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Dense(num_pixels, input_dim=num_pixels, kernel_initializer='normal', activation='relu'))\n",
        "\tmodel.add(Dense(num_classes, kernel_initializer='normal', activation='softmax'))\n",
        "\t# Compile model\n",
        "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\treturn model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kN5TKB0MsHZl",
        "colab_type": "code",
        "outputId": "549e036a-ed39-4b80-ea78-518c41db2edf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        }
      },
      "cell_type": "code",
      "source": [
        "# build the model\n",
        "model = baseline_model()\n",
        "# Fit the model\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200, verbose=2)\n",
        "# Final evaluation of the model\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Baseline Error: %.2f%%\" % (100-scores[1]*100))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            " - 7s - loss: 0.2811 - acc: 0.9207 - val_loss: 0.1411 - val_acc: 0.9573\n",
            "Epoch 2/10\n",
            " - 7s - loss: 0.1117 - acc: 0.9679 - val_loss: 0.0912 - val_acc: 0.9711\n",
            "Epoch 3/10\n",
            " - 7s - loss: 0.0715 - acc: 0.9798 - val_loss: 0.0780 - val_acc: 0.9773\n",
            "Epoch 4/10\n",
            " - 6s - loss: 0.0502 - acc: 0.9859 - val_loss: 0.0745 - val_acc: 0.9767\n",
            "Epoch 5/10\n",
            " - 7s - loss: 0.0372 - acc: 0.9892 - val_loss: 0.0674 - val_acc: 0.9788\n",
            "Epoch 6/10\n",
            " - 7s - loss: 0.0266 - acc: 0.9928 - val_loss: 0.0611 - val_acc: 0.9810\n",
            "Epoch 7/10\n",
            " - 7s - loss: 0.0206 - acc: 0.9947 - val_loss: 0.0616 - val_acc: 0.9809\n",
            "Epoch 8/10\n",
            " - 7s - loss: 0.0140 - acc: 0.9970 - val_loss: 0.0618 - val_acc: 0.9805\n",
            "Epoch 9/10\n",
            " - 7s - loss: 0.0105 - acc: 0.9978 - val_loss: 0.0579 - val_acc: 0.9813\n",
            "Epoch 10/10\n",
            " - 7s - loss: 0.0078 - acc: 0.9987 - val_loss: 0.0578 - val_acc: 0.9820\n",
            "Baseline Error: 1.80%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cVz1_9YPsHel",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "numpy.random.seed(seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5oFzGsmwsHhI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# load data\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "# reshape to be [samples][pixels][width][height]\n",
        "X_train = X_train.reshape(X_train.shape[0], 1, 28, 28).astype('float32')\n",
        "X_test = X_test.reshape(X_test.shape[0], 1, 28, 28).astype('float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "94lbBxfdsHjo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# normalize inputs from 0-255 to 0-1\n",
        "X_train = X_train / 255\n",
        "X_test = X_test / 255\n",
        "# one hot encode outputs\n",
        "y_train = np_utils.to_categorical(y_train)\n",
        "y_test = np_utils.to_categorical(y_test)\n",
        "num_classes = y_test.shape[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "diu-lwdusHmA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def baseline_model():\n",
        "\t# create model\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Conv2D(32, (5, 5), input_shape=(1, 28, 28), activation='relu'))\n",
        "\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\tmodel.add(Dropout(0.2))\n",
        "\tmodel.add(Flatten())\n",
        "\tmodel.add(Dense(128, activation='relu'))\n",
        "\tmodel.add(Dense(num_classes, activation='softmax'))\n",
        "\t# Compile model\n",
        "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\treturn model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uoKiILG5FN0s",
        "colab_type": "code",
        "outputId": "8ea40107-ceda-48d5-b60c-70ded3cefe1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        }
      },
      "cell_type": "code",
      "source": [
        "# build the model\n",
        "model = baseline_model()\n",
        "# Fit the model\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200, verbose=2)\n",
        "# Final evaluation of the model\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"CNN Error: %.2f%%\" % (100-scores[1]*100))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            " - 61s - loss: 0.2253 - acc: 0.9356 - val_loss: 0.0774 - val_acc: 0.9759\n",
            "Epoch 2/10\n",
            " - 61s - loss: 0.0709 - acc: 0.9786 - val_loss: 0.0440 - val_acc: 0.9851\n",
            "Epoch 3/10\n",
            " - 61s - loss: 0.0506 - acc: 0.9846 - val_loss: 0.0432 - val_acc: 0.9852\n",
            "Epoch 4/10\n",
            " - 61s - loss: 0.0389 - acc: 0.9879 - val_loss: 0.0404 - val_acc: 0.9876\n",
            "Epoch 5/10\n",
            " - 61s - loss: 0.0321 - acc: 0.9900 - val_loss: 0.0340 - val_acc: 0.9887\n",
            "Epoch 6/10\n",
            " - 61s - loss: 0.0262 - acc: 0.9918 - val_loss: 0.0333 - val_acc: 0.9890\n",
            "Epoch 7/10\n",
            " - 61s - loss: 0.0216 - acc: 0.9929 - val_loss: 0.0360 - val_acc: 0.9884\n",
            "Epoch 8/10\n",
            " - 61s - loss: 0.0185 - acc: 0.9943 - val_loss: 0.0328 - val_acc: 0.9889\n",
            "Epoch 9/10\n",
            " - 60s - loss: 0.0150 - acc: 0.9953 - val_loss: 0.0328 - val_acc: 0.9891\n",
            "Epoch 10/10\n",
            " - 60s - loss: 0.0137 - acc: 0.9959 - val_loss: 0.0333 - val_acc: 0.9891\n",
            "CNN Error: 1.09%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "SQGRDlpCFN3P",
        "colab_type": "code",
        "outputId": "83fd87e3-98fd-430d-c7a1-a251ccd1b932",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        " ###########################################################\n",
        "  # load data cifar10\n",
        " from keras.datasets import cifar10\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "print(X_train.shape,y_train.shape,X_test.shape,y_test.shape)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 19s 0us/step\n",
            "(50000, 3, 32, 32) (50000, 1) (10000, 3, 32, 32) (10000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "D7pPdHg-FN5w",
        "colab_type": "code",
        "outputId": "09598463-89bd-4238-e9e6-4d55d298bb4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "numpy.random.seed(seed)\n",
        "# flatten 32*32*3 images to a 3072 vector for each image\n",
        "num_pixels = X_train.shape[1] * X_train.shape[2] * X_train.shape[3]\n",
        "print(num_pixels)\n",
        "X_train = X_train.reshape(X_train.shape[0], num_pixels).astype('float32')\n",
        "X_test = X_test.reshape(X_test.shape[0], num_pixels).astype('float32')\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3072\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "m15r04-YFN8G",
        "colab_type": "code",
        "outputId": "2c75dec1-d77d-401b-d8fa-a4539258f648",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "cell_type": "code",
      "source": [
        "# normalize inputs from 0-255 to 0-1\n",
        "X_train = X_train / 255\n",
        "X_test = X_test / 255\n",
        "# one hot encode outputs\n",
        "y_train = np_utils.to_categorical(y_train)\n",
        "y_test = np_utils.to_categorical(y_test)\n",
        "num_classes = y_test.shape[1]\n",
        "# define baseline model\n",
        "def baseline_model():\n",
        "\t# create model\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Dense(num_pixels, input_dim=num_pixels, kernel_initializer='normal', activation='relu'))\n",
        "\tmodel.add(Dense(num_classes, kernel_initializer='normal', activation='softmax'))\n",
        "\t# Compile model\n",
        "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\treturn model\n",
        "\n",
        "# build the model\n",
        "model = baseline_model()\n",
        "# Fit the model\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200, verbose=2)\n",
        "# Final evaluation of the model\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Baseline Error: %.2f%%\" % (100-scores[1]*100))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            " - 72s - loss: 13.1319 - acc: 0.1484 - val_loss: 13.2966 - val_acc: 0.1371\n",
            "Epoch 2/10\n",
            " - 72s - loss: 12.9826 - acc: 0.1609 - val_loss: 13.0714 - val_acc: 0.1494\n",
            "Epoch 3/10\n",
            " - 72s - loss: 13.0585 - acc: 0.1585 - val_loss: 13.0101 - val_acc: 0.1674\n",
            "Epoch 4/10\n",
            " - 72s - loss: 9.1996 - acc: 0.2049 - val_loss: 1.8384 - val_acc: 0.3424\n",
            "Epoch 5/10\n",
            " - 72s - loss: 1.7406 - acc: 0.3792 - val_loss: 1.6886 - val_acc: 0.4001\n",
            "Epoch 6/10\n",
            " - 72s - loss: 1.6374 - acc: 0.4198 - val_loss: 1.5974 - val_acc: 0.4287\n",
            "Epoch 7/10\n",
            " - 72s - loss: 1.5903 - acc: 0.4392 - val_loss: 1.5977 - val_acc: 0.4352\n",
            "Epoch 8/10\n",
            " - 71s - loss: 1.5395 - acc: 0.4556 - val_loss: 1.5403 - val_acc: 0.4585\n",
            "Epoch 9/10\n",
            " - 71s - loss: 1.5072 - acc: 0.4663 - val_loss: 1.5686 - val_acc: 0.4415\n",
            "Epoch 10/10\n",
            " - 72s - loss: 1.4723 - acc: 0.4802 - val_loss: 1.5204 - val_acc: 0.4588\n",
            "Baseline Error: 54.12%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8c_1qUXhFN-g",
        "colab_type": "code",
        "outputId": "c195c79e-d9c0-4625-c20a-68862cf1ea97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "X_train = X_train.reshape(X_train.shape[0], 3, 32, 32).astype('float32')\n",
        "X_test = X_test.reshape(X_test.shape[0], 3, 32, 32).astype('float32')\n",
        "# normalize inputs from 0-255 to 0-1\n",
        "X_train = X_train / 255\n",
        "X_test = X_test / 255\n",
        "# one hot encode outputs\n",
        "y_train = np_utils.to_categorical(y_train)\n",
        "y_test = np_utils.to_categorical(y_test)\n",
        "num_classes = y_test.shape[1]\n",
        "\n",
        "def baseline_model():\n",
        "\t# create model\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Conv2D(32, (5, 5), input_shape=(3, 32, 32), activation='relu'))\n",
        "\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\tmodel.add(Dropout(0.2))\n",
        "\tmodel.add(Flatten())\n",
        "\tmodel.add(Dense(128, activation='relu'))\n",
        "\tmodel.add(Dense(num_classes, activation='softmax'))\n",
        "\t# Compile model\n",
        "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\treturn model\n",
        "print(num_classes)\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "iqPUx39PFOBD",
        "colab_type": "code",
        "outputId": "d25e481c-98c7-4688-fdf1-f519b9e97a4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "cell_type": "code",
      "source": [
        "# build the model\n",
        "model = baseline_model()\n",
        "# Fit the model\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200, verbose=2)\n",
        "# Final evaluation of the model\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"CNN Error: %.2f%%\" % (100-scores[1]*100))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            " - 94s - loss: 1.5828 - acc: 0.4329 - val_loss: 1.3342 - val_acc: 0.5314\n",
            "Epoch 2/10\n",
            " - 92s - loss: 1.2802 - acc: 0.5497 - val_loss: 1.2424 - val_acc: 0.5567\n",
            "Epoch 3/10\n",
            " - 92s - loss: 1.1645 - acc: 0.5926 - val_loss: 1.1517 - val_acc: 0.5944\n",
            "Epoch 4/10\n",
            " - 93s - loss: 1.0836 - acc: 0.6222 - val_loss: 1.1268 - val_acc: 0.6066\n",
            "Epoch 5/10\n",
            " - 92s - loss: 1.0267 - acc: 0.6412 - val_loss: 1.0697 - val_acc: 0.6240\n",
            "Epoch 6/10\n",
            " - 92s - loss: 0.9674 - acc: 0.6626 - val_loss: 1.0494 - val_acc: 0.6349\n",
            "Epoch 7/10\n",
            " - 93s - loss: 0.9339 - acc: 0.6769 - val_loss: 1.0121 - val_acc: 0.6477\n",
            "Epoch 8/10\n",
            " - 92s - loss: 0.8987 - acc: 0.6876 - val_loss: 1.0159 - val_acc: 0.6422\n",
            "Epoch 9/10\n",
            " - 92s - loss: 0.8646 - acc: 0.6989 - val_loss: 1.0165 - val_acc: 0.6535\n",
            "Epoch 10/10\n",
            " - 92s - loss: 0.8313 - acc: 0.7105 - val_loss: 0.9854 - val_acc: 0.6624\n",
            "CNN Error: 33.76%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YTtE-vSGFOFg",
        "colab_type": "code",
        "outputId": "bd3c4590-861a-4d4e-e6b3-5ffa60b5e5ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "#Load Training and Test data\n",
        "# Input image dimensions.\n",
        "input_shape = X_train.shape[1:]\n",
        "\n",
        "# Normalize data.\n",
        "X_train = X_train.astype('float32') / 255\n",
        "X_test = X_test.astype('float32') / 255\n",
        "# Convert class vectors to binary class matrices.\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "print(X_train.shape,X_test.shape,y_train.shape,y_test.shape)\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 3, 32, 32) (10000, 3, 32, 32) (50000, 10) (10000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Ff4VM4A8dMhg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "212c5c2f-b05c-4f8a-c971-90f2c22712cd"
      },
      "cell_type": "code",
      "source": [
        "# a = resize_image_arr(X_train)\n",
        "# a1 = resize_image_arr(X_test)\n",
        "# b = resize_image_arr(y_train)\n",
        "# b1 = resize_image_arr(y_test)\n",
        "# print(a.shape,a1.shape,b.shape,b1.shape)\n",
        "import scipy\n",
        "new_shape = (64,64,3)\n",
        "X_train_new = np.empty(shape=(X_train.shape[0],)+new_shape)\n",
        "for idx in range(X_train.shape[0]):\n",
        "    X_train_new[idx] = scipy.misc.imresize(X_train[idx], new_shape)\n",
        "\n",
        "X_test_new = np.empty(shape=(X_test.shape[0],)+new_shape)\n",
        "for idx in range(X_test.shape[0]):\n",
        "    X_test_new[idx] = scipy.misc.imresize(X_test[idx], new_shape)\n"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: `imresize` is deprecated!\n",
            "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
            "Use ``skimage.transform.resize`` instead.\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: DeprecationWarning: `imresize` is deprecated!\n",
            "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
            "Use ``skimage.transform.resize`` instead.\n",
            "  if __name__ == '__main__':\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "gh8lJ4dqFOIY",
        "colab_type": "code",
        "outputId": "6de2072d-a446-4f9a-910e-ee29c051cdcd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "cell_type": "code",
      "source": [
        "# print(X_train_new.shape,X_test_new.shape,y_train.shape,y_test.shape)\n",
        "img_height,img_width = 32,32 \n",
        "num_classes = 10\n",
        "#If imagenet weights are being loaded, \n",
        "#input must have a static square shape (one of (128, 128), (160, 160), (192, 192), or (224, 224))\n",
        "base_model = applications.resnet50.ResNet50(weights= None, include_top=False, input_shape= (3,32,32))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
            "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "QADptY0xFOKy",
        "colab_type": "code",
        "outputId": "55804ade-072e-4ac3-f076-926faead79e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1054
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.optimizers import SGD, Adam\n",
        "# sgd = SGD(lr=lrate, momentum=0.9, decay=decay, nesterov=False)\n",
        "adam = Adam(lr=0.0001)\n",
        "model.compile(optimizer= adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(X_train, y_train, epochs = 30, batch_size = 64)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "50000/50000 [==============================] - 95s 2ms/step - loss: 0.7402 - acc: 0.7449\n",
            "Epoch 2/30\n",
            "50000/50000 [==============================] - 92s 2ms/step - loss: 0.7310 - acc: 0.7485\n",
            "Epoch 3/30\n",
            "50000/50000 [==============================] - 93s 2ms/step - loss: 0.7222 - acc: 0.7522\n",
            "Epoch 4/30\n",
            "50000/50000 [==============================] - 92s 2ms/step - loss: 0.7127 - acc: 0.7558\n",
            "Epoch 5/30\n",
            "50000/50000 [==============================] - 92s 2ms/step - loss: 0.7033 - acc: 0.7572\n",
            "Epoch 6/30\n",
            "50000/50000 [==============================] - 93s 2ms/step - loss: 0.6943 - acc: 0.7598\n",
            "Epoch 7/30\n",
            "50000/50000 [==============================] - 92s 2ms/step - loss: 0.6891 - acc: 0.7643\n",
            "Epoch 8/30\n",
            "50000/50000 [==============================] - 92s 2ms/step - loss: 0.6817 - acc: 0.7660\n",
            "Epoch 9/30\n",
            "50000/50000 [==============================] - 93s 2ms/step - loss: 0.6711 - acc: 0.7693\n",
            "Epoch 10/30\n",
            "50000/50000 [==============================] - 92s 2ms/step - loss: 0.6675 - acc: 0.7704\n",
            "Epoch 11/30\n",
            "50000/50000 [==============================] - 92s 2ms/step - loss: 0.6599 - acc: 0.7732\n",
            "Epoch 12/30\n",
            "50000/50000 [==============================] - 92s 2ms/step - loss: 0.6522 - acc: 0.7755\n",
            "Epoch 13/30\n",
            "50000/50000 [==============================] - 94s 2ms/step - loss: 0.6455 - acc: 0.7770\n",
            "Epoch 14/30\n",
            "50000/50000 [==============================] - 92s 2ms/step - loss: 0.6386 - acc: 0.7806\n",
            "Epoch 15/30\n",
            "50000/50000 [==============================] - 92s 2ms/step - loss: 0.6299 - acc: 0.7827\n",
            "Epoch 16/30\n",
            "50000/50000 [==============================] - 94s 2ms/step - loss: 0.6267 - acc: 0.7838\n",
            "Epoch 17/30\n",
            "50000/50000 [==============================] - 92s 2ms/step - loss: 0.6178 - acc: 0.7875\n",
            "Epoch 18/30\n",
            "50000/50000 [==============================] - 92s 2ms/step - loss: 0.6107 - acc: 0.7895\n",
            "Epoch 19/30\n",
            "50000/50000 [==============================] - 93s 2ms/step - loss: 0.6053 - acc: 0.7908\n",
            "Epoch 20/30\n",
            "50000/50000 [==============================] - 92s 2ms/step - loss: 0.5997 - acc: 0.7940\n",
            "Epoch 21/30\n",
            "50000/50000 [==============================] - 89s 2ms/step - loss: 0.5939 - acc: 0.7953\n",
            "Epoch 22/30\n",
            "50000/50000 [==============================] - 89s 2ms/step - loss: 0.5872 - acc: 0.7987\n",
            "Epoch 23/30\n",
            "50000/50000 [==============================] - 91s 2ms/step - loss: 0.5785 - acc: 0.8002\n",
            "Epoch 24/30\n",
            "50000/50000 [==============================] - 91s 2ms/step - loss: 0.5718 - acc: 0.8038\n",
            "Epoch 25/30\n",
            "50000/50000 [==============================] - 89s 2ms/step - loss: 0.5670 - acc: 0.8049\n",
            "Epoch 26/30\n",
            "50000/50000 [==============================] - 91s 2ms/step - loss: 0.5620 - acc: 0.8082\n",
            "Epoch 27/30\n",
            "50000/50000 [==============================] - 91s 2ms/step - loss: 0.5559 - acc: 0.8106\n",
            "Epoch 28/30\n",
            "50000/50000 [==============================] - 91s 2ms/step - loss: 0.5511 - acc: 0.8108\n",
            "Epoch 29/30\n",
            "50000/50000 [==============================] - 91s 2ms/step - loss: 0.5471 - acc: 0.8117\n",
            "Epoch 30/30\n",
            "50000/50000 [==============================] - 92s 2ms/step - loss: 0.5428 - acc: 0.8140\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f79ada6d908>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "metadata": {
        "id": "I8VcLIAcFOM_",
        "colab_type": "code",
        "outputId": "14194d7e-e40b-464e-8e98-e7e6e052a988",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "preds = model.evaluate(X_test, y_test)\n",
        "print (\"Loss = \" + str(preds[0]))\n",
        "print (\"Test Accuracy = \" + str(preds[1]))\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 10s 983us/step\n",
            "Loss = 0.9669310068130493\n",
            "Test Accuracy = 0.6826\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}