{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MP3_yun.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "SYZkwPO5rdK6",
        "colab_type": "code",
        "outputId": "c88ee571-0ae7-4e3d-c0c1-ee61c9bf1373",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "cell_type": "code",
      "source": [
        "# Plot ad hoc mnist instances\n",
        "from keras.datasets import mnist\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import numpy\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.utils import np_utils\n",
        "import keras\n",
        "import numpy as np\n",
        "from keras.datasets import cifar10\n",
        "from keras.applications.resnet50 import ResNet50\n",
        "from keras.layers import GlobalAveragePooling2D, Dense\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers import Dense\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Model\n",
        "from skimage.transform import resize\n",
        "from IPython import embed\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from urllib.request import urlopen,urlretrieve\n",
        "from PIL import Image\n",
        "from tqdm import tqdm_notebook\n",
        "%matplotlib inline\n",
        "from sklearn.utils import shuffle\n",
        "import cv2\n",
        "\n",
        "from keras.models import load_model\n",
        "from sklearn.datasets import load_files   \n",
        "from keras.utils import np_utils\n",
        "from glob import glob\n",
        "from keras import applications\n",
        "from keras.preprocessing.image import ImageDataGenerator \n",
        "from keras import optimizers\n",
        "from keras.models import Sequential,Model,load_model\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D,GlobalAveragePooling2D\n",
        "from keras.callbacks import TensorBoard,ReduceLROnPlateau,ModelCheckpoint\n",
        "\n",
        "\n",
        "import numpy\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Flatten\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.utils import np_utils\n",
        "from keras import backend as K\n",
        "K.set_image_dim_ordering('th')\n",
        "\n",
        "# load (downloaded if needed) the MNIST dataset\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "# plot 4 images as gray scale\n",
        "plt.subplot(221)\n",
        "plt.imshow(X_train[0], cmap=plt.get_cmap('gray'))\n",
        "plt.subplot(222)\n",
        "plt.imshow(X_train[1], cmap=plt.get_cmap('gray'))\n",
        "plt.subplot(223)\n",
        "plt.imshow(X_train[2], cmap=plt.get_cmap('gray'))\n",
        "plt.subplot(224)\n",
        "plt.imshow(X_train[3], cmap=plt.get_cmap('gray'))\n",
        "# show the plot\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAT4AAAD8CAYAAADub8g7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 4 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "f0hiBHBjr-es",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "numpy.random.seed(seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PNVdkf4osHGn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# load data\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fG8ARKc7sHOo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# flatten 28*28 images to a 784 vector for each image\n",
        "num_pixels = X_train.shape[1] * X_train.shape[2]\n",
        "X_train = X_train.reshape(X_train.shape[0], num_pixels).astype('float32')\n",
        "X_test = X_test.reshape(X_test.shape[0], num_pixels).astype('float32')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rNf831fSsHRj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# normalize inputs from 0-255 to 0-1\n",
        "X_train = X_train / 255\n",
        "X_test = X_test / 255\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qj1aon9isHUb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# one hot encode outputs\n",
        "y_train = np_utils.to_categorical(y_train)\n",
        "y_test = np_utils.to_categorical(y_test)\n",
        "num_classes = y_test.shape[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "flDzIfNQsHXC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# define baseline model\n",
        "def baseline_model():\n",
        "\t# create model\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Dense(num_pixels, input_dim=num_pixels, kernel_initializer='normal', activation='relu'))\n",
        "\tmodel.add(Dense(num_classes, kernel_initializer='normal', activation='softmax'))\n",
        "\t# Compile model\n",
        "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\treturn model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kN5TKB0MsHZl",
        "colab_type": "code",
        "outputId": "7f9199a4-1559-425d-b2ae-a2088088c729",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1142
        }
      },
      "cell_type": "code",
      "source": [
        "# build the model\n",
        "model = baseline_model()\n",
        "# Fit the model\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=30, batch_size=200, verbose=2)\n",
        "# Final evaluation of the model\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Baseline Error: %.2f%%\" % (100-scores[1]*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/30\n",
            " - 24s - loss: 0.2810 - acc: 0.9206 - val_loss: 0.1414 - val_acc: 0.9571\n",
            "Epoch 2/30\n",
            " - 9s - loss: 0.1115 - acc: 0.9678 - val_loss: 0.0914 - val_acc: 0.9715\n",
            "Epoch 3/30\n",
            " - 9s - loss: 0.0715 - acc: 0.9799 - val_loss: 0.0783 - val_acc: 0.9775\n",
            "Epoch 4/30\n",
            " - 9s - loss: 0.0504 - acc: 0.9858 - val_loss: 0.0749 - val_acc: 0.9764\n",
            "Epoch 5/30\n",
            " - 8s - loss: 0.0372 - acc: 0.9893 - val_loss: 0.0676 - val_acc: 0.9793\n",
            "Epoch 6/30\n",
            " - 9s - loss: 0.0267 - acc: 0.9928 - val_loss: 0.0630 - val_acc: 0.9802\n",
            "Epoch 7/30\n",
            " - 9s - loss: 0.0206 - acc: 0.9948 - val_loss: 0.0610 - val_acc: 0.9810\n",
            "Epoch 8/30\n",
            " - 8s - loss: 0.0140 - acc: 0.9970 - val_loss: 0.0618 - val_acc: 0.9801\n",
            "Epoch 9/30\n",
            " - 8s - loss: 0.0108 - acc: 0.9977 - val_loss: 0.0575 - val_acc: 0.9821\n",
            "Epoch 10/30\n",
            " - 8s - loss: 0.0076 - acc: 0.9988 - val_loss: 0.0577 - val_acc: 0.9820\n",
            "Epoch 11/30\n",
            " - 8s - loss: 0.0067 - acc: 0.9988 - val_loss: 0.0636 - val_acc: 0.9809\n",
            "Epoch 12/30\n",
            " - 8s - loss: 0.0049 - acc: 0.9991 - val_loss: 0.0568 - val_acc: 0.9832\n",
            "Epoch 13/30\n",
            " - 8s - loss: 0.0033 - acc: 0.9996 - val_loss: 0.0634 - val_acc: 0.9823\n",
            "Epoch 14/30\n",
            " - 8s - loss: 0.0039 - acc: 0.9992 - val_loss: 0.0775 - val_acc: 0.9776\n",
            "Epoch 15/30\n",
            " - 8s - loss: 0.0130 - acc: 0.9958 - val_loss: 0.0737 - val_acc: 0.9793\n",
            "Epoch 16/30\n",
            " - 8s - loss: 0.0063 - acc: 0.9982 - val_loss: 0.0797 - val_acc: 0.9780\n",
            "Epoch 17/30\n",
            " - 8s - loss: 0.0041 - acc: 0.9992 - val_loss: 0.0739 - val_acc: 0.9814\n",
            "Epoch 18/30\n",
            " - 9s - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0631 - val_acc: 0.9829\n",
            "Epoch 19/30\n",
            " - 8s - loss: 5.0965e-04 - acc: 1.0000 - val_loss: 0.0630 - val_acc: 0.9843\n",
            "Epoch 20/30\n",
            " - 8s - loss: 3.7617e-04 - acc: 1.0000 - val_loss: 0.0639 - val_acc: 0.9841\n",
            "Epoch 21/30\n",
            " - 8s - loss: 3.0279e-04 - acc: 1.0000 - val_loss: 0.0635 - val_acc: 0.9844\n",
            "Epoch 22/30\n",
            " - 8s - loss: 2.6914e-04 - acc: 1.0000 - val_loss: 0.0645 - val_acc: 0.9840\n",
            "Epoch 23/30\n",
            " - 8s - loss: 2.3515e-04 - acc: 1.0000 - val_loss: 0.0658 - val_acc: 0.9843\n",
            "Epoch 24/30\n",
            " - 9s - loss: 2.0567e-04 - acc: 1.0000 - val_loss: 0.0657 - val_acc: 0.9836\n",
            "Epoch 25/30\n",
            " - 9s - loss: 1.8687e-04 - acc: 1.0000 - val_loss: 0.0655 - val_acc: 0.9843\n",
            "Epoch 26/30\n",
            " - 8s - loss: 1.7201e-04 - acc: 1.0000 - val_loss: 0.0695 - val_acc: 0.9832\n",
            "Epoch 27/30\n",
            " - 8s - loss: 0.0266 - acc: 0.9913 - val_loss: 0.0721 - val_acc: 0.9815\n",
            "Epoch 28/30\n",
            " - 8s - loss: 0.0056 - acc: 0.9984 - val_loss: 0.0768 - val_acc: 0.9811\n",
            "Epoch 29/30\n",
            " - 8s - loss: 0.0016 - acc: 0.9997 - val_loss: 0.0660 - val_acc: 0.9839\n",
            "Epoch 30/30\n",
            " - 8s - loss: 5.2554e-04 - acc: 1.0000 - val_loss: 0.0682 - val_acc: 0.9833\n",
            "Baseline Error: 1.67%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cVz1_9YPsHel",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "numpy.random.seed(seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5oFzGsmwsHhI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# load data\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "# reshape to be [samples][pixels][width][height]\n",
        "X_train = X_train.reshape(X_train.shape[0], 1, 28, 28).astype('float32')\n",
        "X_test = X_test.reshape(X_test.shape[0], 1, 28, 28).astype('float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "94lbBxfdsHjo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# normalize inputs from 0-255 to 0-1\n",
        "X_train = X_train / 255\n",
        "X_test = X_test / 255\n",
        "# one hot encode outputs\n",
        "y_train = np_utils.to_categorical(y_train)\n",
        "y_test = np_utils.to_categorical(y_test)\n",
        "num_classes = y_test.shape[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "diu-lwdusHmA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def baseline_model():\n",
        "\t# create model\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Conv2D(32, (5, 5), input_shape=(1, 28, 28), activation='relu'))\n",
        "\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\tmodel.add(Dropout(0.2))\n",
        "\tmodel.add(Flatten())\n",
        "\tmodel.add(Dense(128, activation='relu'))\n",
        "\tmodel.add(Dense(num_classes, activation='softmax'))\n",
        "\t# Compile model\n",
        "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\treturn model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uoKiILG5FN0s",
        "colab_type": "code",
        "outputId": "ba486fb2-b4c6-4021-f3dc-df971dd419ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1142
        }
      },
      "cell_type": "code",
      "source": [
        "# build the model\n",
        "model = baseline_model()\n",
        "# Fit the model\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=30, batch_size=200, verbose=2)\n",
        "# Final evaluation of the model\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"CNN Error: %.2f%%\" % (100-scores[1]*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/30\n",
            " - 64s - loss: 0.2253 - acc: 0.9356 - val_loss: 0.0774 - val_acc: 0.9759\n",
            "Epoch 2/30\n",
            " - 64s - loss: 0.0709 - acc: 0.9786 - val_loss: 0.0441 - val_acc: 0.9851\n",
            "Epoch 3/30\n",
            " - 63s - loss: 0.0507 - acc: 0.9846 - val_loss: 0.0433 - val_acc: 0.9857\n",
            "Epoch 4/30\n",
            " - 62s - loss: 0.0389 - acc: 0.9880 - val_loss: 0.0403 - val_acc: 0.9872\n",
            "Epoch 5/30\n",
            " - 61s - loss: 0.0321 - acc: 0.9899 - val_loss: 0.0338 - val_acc: 0.9887\n",
            "Epoch 6/30\n",
            " - 61s - loss: 0.0264 - acc: 0.9919 - val_loss: 0.0324 - val_acc: 0.9893\n",
            "Epoch 7/30\n",
            " - 61s - loss: 0.0216 - acc: 0.9931 - val_loss: 0.0351 - val_acc: 0.9887\n",
            "Epoch 8/30\n",
            " - 61s - loss: 0.0187 - acc: 0.9944 - val_loss: 0.0328 - val_acc: 0.9890\n",
            "Epoch 9/30\n",
            " - 62s - loss: 0.0151 - acc: 0.9951 - val_loss: 0.0318 - val_acc: 0.9891\n",
            "Epoch 10/30\n",
            " - 61s - loss: 0.0138 - acc: 0.9960 - val_loss: 0.0330 - val_acc: 0.9893\n",
            "Epoch 11/30\n",
            " - 60s - loss: 0.0118 - acc: 0.9960 - val_loss: 0.0319 - val_acc: 0.9893\n",
            "Epoch 12/30\n",
            " - 61s - loss: 0.0106 - acc: 0.9962 - val_loss: 0.0343 - val_acc: 0.9893\n",
            "Epoch 13/30\n",
            " - 60s - loss: 0.0091 - acc: 0.9968 - val_loss: 0.0325 - val_acc: 0.9899\n",
            "Epoch 14/30\n",
            " - 62s - loss: 0.0093 - acc: 0.9969 - val_loss: 0.0415 - val_acc: 0.9876\n",
            "Epoch 15/30\n",
            " - 62s - loss: 0.0072 - acc: 0.9975 - val_loss: 0.0317 - val_acc: 0.9906\n",
            "Epoch 16/30\n",
            " - 61s - loss: 0.0062 - acc: 0.9978 - val_loss: 0.0332 - val_acc: 0.9905\n",
            "Epoch 17/30\n",
            " - 62s - loss: 0.0060 - acc: 0.9981 - val_loss: 0.0406 - val_acc: 0.9893\n",
            "Epoch 18/30\n",
            " - 61s - loss: 0.0052 - acc: 0.9981 - val_loss: 0.0411 - val_acc: 0.9895\n",
            "Epoch 19/30\n",
            " - 62s - loss: 0.0050 - acc: 0.9982 - val_loss: 0.0394 - val_acc: 0.9905\n",
            "Epoch 20/30\n",
            " - 61s - loss: 0.0059 - acc: 0.9979 - val_loss: 0.0326 - val_acc: 0.9906\n",
            "Epoch 21/30\n",
            " - 61s - loss: 0.0042 - acc: 0.9986 - val_loss: 0.0431 - val_acc: 0.9896\n",
            "Epoch 22/30\n",
            " - 63s - loss: 0.0043 - acc: 0.9986 - val_loss: 0.0395 - val_acc: 0.9909\n",
            "Epoch 23/30\n",
            " - 61s - loss: 0.0041 - acc: 0.9987 - val_loss: 0.0404 - val_acc: 0.9900\n",
            "Epoch 24/30\n",
            " - 63s - loss: 0.0030 - acc: 0.9990 - val_loss: 0.0359 - val_acc: 0.9907\n",
            "Epoch 25/30\n",
            " - 60s - loss: 0.0035 - acc: 0.9989 - val_loss: 0.0343 - val_acc: 0.9909\n",
            "Epoch 26/30\n",
            " - 60s - loss: 0.0037 - acc: 0.9987 - val_loss: 0.0477 - val_acc: 0.9887\n",
            "Epoch 27/30\n",
            " - 61s - loss: 0.0039 - acc: 0.9986 - val_loss: 0.0447 - val_acc: 0.9887\n",
            "Epoch 28/30\n",
            " - 61s - loss: 0.0036 - acc: 0.9988 - val_loss: 0.0401 - val_acc: 0.9893\n",
            "Epoch 29/30\n",
            " - 62s - loss: 0.0024 - acc: 0.9993 - val_loss: 0.0377 - val_acc: 0.9899\n",
            "Epoch 30/30\n",
            " - 61s - loss: 0.0023 - acc: 0.9992 - val_loss: 0.0381 - val_acc: 0.9903\n",
            "CNN Error: 0.97%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "SQGRDlpCFN3P",
        "colab_type": "code",
        "outputId": "21be14ea-f5fa-4f7a-9190-23abfbf6003b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        " ###########################################################\n",
        "  # load data cifar10\n",
        " from keras.datasets import cifar10\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "print(X_train.shape,y_train.shape,X_test.shape,y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 28s 0us/step\n",
            "(50000, 3, 32, 32) (50000, 1) (10000, 3, 32, 32) (10000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "D7pPdHg-FN5w",
        "colab_type": "code",
        "outputId": "ffb42017-ffa1-4b29-a427-74066a09d922",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "numpy.random.seed(seed)\n",
        "# flatten 32*32*3 images to a 3072 vector for each image\n",
        "num_pixels = X_train.shape[1] * X_train.shape[2] * X_train.shape[3]\n",
        "print(num_pixels)\n",
        "X_train = X_train.reshape(X_train.shape[0], num_pixels).astype('float32')\n",
        "X_test = X_test.reshape(X_test.shape[0], num_pixels).astype('float32')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3072\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "m15r04-YFN8G",
        "colab_type": "code",
        "outputId": "7ebba735-6317-49e0-e380-185bded5aea2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1071
        }
      },
      "cell_type": "code",
      "source": [
        "# normalize inputs from 0-255 to 0-1\n",
        "X_train = X_train / 255\n",
        "X_test = X_test / 255\n",
        "# one hot encode outputs\n",
        "y_train = np_utils.to_categorical(y_train)\n",
        "y_test = np_utils.to_categorical(y_test)\n",
        "num_classes = y_test.shape[1]\n",
        "# define baseline model\n",
        "def baseline_model():\n",
        "\t# create model\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Dense(num_pixels, input_dim=num_pixels, kernel_initializer='normal', activation='relu'))\n",
        "\tmodel.add(Dense(num_classes, kernel_initializer='normal', activation='softmax'))\n",
        "\t# Compile model\n",
        "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\treturn model\n",
        "\n",
        "# build the model\n",
        "model = baseline_model()\n",
        "# Fit the model\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=30, batch_size=200, verbose=2)\n",
        "# Final evaluation of the model\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Baseline Error: %.2f%%\" % (100-scores[1]*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/30\n",
            " - 69s - loss: 13.1319 - acc: 0.1484 - val_loss: 13.2966 - val_acc: 0.1371\n",
            "Epoch 2/30\n",
            " - 67s - loss: 12.9822 - acc: 0.1609 - val_loss: 13.1366 - val_acc: 0.1413\n",
            "Epoch 3/30\n",
            " - 69s - loss: 12.9728 - acc: 0.1583 - val_loss: 11.9610 - val_acc: 0.1758\n",
            "Epoch 4/30\n",
            " - 68s - loss: 7.1997 - acc: 0.2362 - val_loss: 1.8351 - val_acc: 0.3472\n",
            "Epoch 5/30\n",
            " - 68s - loss: 1.7366 - acc: 0.3817 - val_loss: 1.6801 - val_acc: 0.4051\n",
            "Epoch 6/30\n",
            " - 68s - loss: 1.6418 - acc: 0.4170 - val_loss: 1.6171 - val_acc: 0.4277\n",
            "Epoch 7/30\n",
            " - 71s - loss: 1.5915 - acc: 0.4404 - val_loss: 1.6131 - val_acc: 0.4265\n",
            "Epoch 8/30\n",
            " - 71s - loss: 1.5450 - acc: 0.4559 - val_loss: 1.5518 - val_acc: 0.4506\n",
            "Epoch 9/30\n",
            " - 69s - loss: 1.5072 - acc: 0.4680 - val_loss: 1.5435 - val_acc: 0.4550\n",
            "Epoch 10/30\n",
            " - 71s - loss: 1.4748 - acc: 0.4818 - val_loss: 1.5200 - val_acc: 0.4526\n",
            "Epoch 11/30\n",
            " - 69s - loss: 1.4483 - acc: 0.4881 - val_loss: 1.4791 - val_acc: 0.4745\n",
            "Epoch 12/30\n",
            " - 70s - loss: 1.4260 - acc: 0.4965 - val_loss: 1.4747 - val_acc: 0.4717\n",
            "Epoch 13/30\n",
            " - 67s - loss: 1.4067 - acc: 0.5027 - val_loss: 1.4491 - val_acc: 0.4853\n",
            "Epoch 14/30\n",
            " - 68s - loss: 1.3765 - acc: 0.5177 - val_loss: 1.4451 - val_acc: 0.4847\n",
            "Epoch 15/30\n",
            " - 68s - loss: 1.3633 - acc: 0.5191 - val_loss: 1.4409 - val_acc: 0.4879\n",
            "Epoch 16/30\n",
            " - 68s - loss: 1.3423 - acc: 0.5251 - val_loss: 1.4445 - val_acc: 0.4836\n",
            "Epoch 17/30\n",
            " - 67s - loss: 1.3340 - acc: 0.5289 - val_loss: 1.4295 - val_acc: 0.4979\n",
            "Epoch 18/30\n",
            " - 67s - loss: 1.3219 - acc: 0.5348 - val_loss: 1.5342 - val_acc: 0.4651\n",
            "Epoch 19/30\n",
            " - 66s - loss: 1.3023 - acc: 0.5391 - val_loss: 1.3935 - val_acc: 0.5075\n",
            "Epoch 20/30\n",
            " - 66s - loss: 1.2889 - acc: 0.5445 - val_loss: 1.4266 - val_acc: 0.5002\n",
            "Epoch 21/30\n",
            " - 67s - loss: 1.2724 - acc: 0.5515 - val_loss: 1.4136 - val_acc: 0.5077\n",
            "Epoch 22/30\n",
            " - 66s - loss: 1.2657 - acc: 0.5541 - val_loss: 1.4022 - val_acc: 0.5004\n",
            "Epoch 23/30\n",
            " - 67s - loss: 1.2474 - acc: 0.5614 - val_loss: 1.4051 - val_acc: 0.5078\n",
            "Epoch 24/30\n",
            " - 67s - loss: 1.2307 - acc: 0.5672 - val_loss: 1.4562 - val_acc: 0.4915\n",
            "Epoch 25/30\n",
            " - 69s - loss: 1.2224 - acc: 0.5669 - val_loss: 1.3950 - val_acc: 0.5057\n",
            "Epoch 26/30\n",
            " - 70s - loss: 1.2167 - acc: 0.5712 - val_loss: 1.3906 - val_acc: 0.5132\n",
            "Epoch 27/30\n",
            " - 68s - loss: 1.1970 - acc: 0.5771 - val_loss: 1.4153 - val_acc: 0.5072\n",
            "Epoch 28/30\n",
            " - 68s - loss: 1.1940 - acc: 0.5785 - val_loss: 1.4155 - val_acc: 0.5039\n",
            "Epoch 29/30\n",
            " - 69s - loss: 1.1741 - acc: 0.5861 - val_loss: 1.3919 - val_acc: 0.5190\n",
            "Epoch 30/30\n",
            " - 68s - loss: 1.1649 - acc: 0.5890 - val_loss: 1.4030 - val_acc: 0.5109\n",
            "Baseline Error: 48.91%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8c_1qUXhFN-g",
        "colab_type": "code",
        "outputId": "f1846a7a-9b1a-4cbb-a047-54b6f3dd48fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "X_train = X_train.reshape(X_train.shape[0], 3, 32, 32).astype('float32')\n",
        "X_test = X_test.reshape(X_test.shape[0], 3, 32, 32).astype('float32')\n",
        "# normalize inputs from 0-255 to 0-1\n",
        "X_train = X_train / 255\n",
        "X_test = X_test / 255\n",
        "# one hot encode outputs\n",
        "y_train = np_utils.to_categorical(y_train)\n",
        "y_test = np_utils.to_categorical(y_test)\n",
        "num_classes = y_test.shape[1]\n",
        "\n",
        "def baseline_model():\n",
        "\t# create model\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Conv2D(32, (5, 5), input_shape=(3, 32, 32), activation='relu'))\n",
        "\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\tmodel.add(Dropout(0.2))\n",
        "\tmodel.add(Flatten())\n",
        "\tmodel.add(Dense(128, activation='relu'))\n",
        "\tmodel.add(Dense(num_classes, activation='softmax'))\n",
        "\t# Compile model\n",
        "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\treturn model\n",
        "print(num_classes)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "iqPUx39PFOBD",
        "colab_type": "code",
        "outputId": "ecc8c620-561e-4474-a0ee-93081293c861",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1071
        }
      },
      "cell_type": "code",
      "source": [
        "# build the model\n",
        "model = baseline_model()\n",
        "# Fit the model\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=30, batch_size=200, verbose=2)\n",
        "# Final evaluation of the model\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"CNN Error: %.2f%%\" % (100-scores[1]*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/30\n",
            " - 87s - loss: 1.6357 - acc: 0.4171 - val_loss: 1.3765 - val_acc: 0.5099\n",
            "Epoch 2/30\n",
            " - 86s - loss: 1.3221 - acc: 0.5311 - val_loss: 1.2540 - val_acc: 0.5634\n",
            "Epoch 3/30\n",
            " - 87s - loss: 1.2025 - acc: 0.5767 - val_loss: 1.1771 - val_acc: 0.5875\n",
            "Epoch 4/30\n",
            " - 86s - loss: 1.1263 - acc: 0.6061 - val_loss: 1.1164 - val_acc: 0.6101\n",
            "Epoch 5/30\n",
            " - 86s - loss: 1.0647 - acc: 0.6283 - val_loss: 1.0792 - val_acc: 0.6208\n",
            "Epoch 6/30\n",
            " - 86s - loss: 1.0185 - acc: 0.6461 - val_loss: 1.1029 - val_acc: 0.6139\n",
            "Epoch 7/30\n",
            " - 87s - loss: 0.9740 - acc: 0.6617 - val_loss: 1.0422 - val_acc: 0.6369\n",
            "Epoch 8/30\n",
            " - 87s - loss: 0.9358 - acc: 0.6734 - val_loss: 1.0789 - val_acc: 0.6226\n",
            "Epoch 9/30\n",
            " - 86s - loss: 0.9042 - acc: 0.6836 - val_loss: 1.0093 - val_acc: 0.6509\n",
            "Epoch 10/30\n",
            " - 86s - loss: 0.8713 - acc: 0.6973 - val_loss: 0.9949 - val_acc: 0.6560\n",
            "Epoch 11/30\n",
            " - 86s - loss: 0.8500 - acc: 0.7036 - val_loss: 1.0002 - val_acc: 0.6568\n",
            "Epoch 12/30\n",
            " - 87s - loss: 0.8145 - acc: 0.7154 - val_loss: 1.0085 - val_acc: 0.6454\n",
            "Epoch 13/30\n",
            " - 86s - loss: 0.7934 - acc: 0.7240 - val_loss: 1.0003 - val_acc: 0.6520\n",
            "Epoch 14/30\n",
            " - 86s - loss: 0.7677 - acc: 0.7323 - val_loss: 0.9931 - val_acc: 0.6600\n",
            "Epoch 15/30\n",
            " - 85s - loss: 0.7432 - acc: 0.7420 - val_loss: 0.9763 - val_acc: 0.6664\n",
            "Epoch 16/30\n",
            " - 85s - loss: 0.7210 - acc: 0.7496 - val_loss: 1.0188 - val_acc: 0.6540\n",
            "Epoch 17/30\n",
            " - 86s - loss: 0.7042 - acc: 0.7549 - val_loss: 1.0020 - val_acc: 0.6597\n",
            "Epoch 18/30\n",
            " - 86s - loss: 0.6830 - acc: 0.7614 - val_loss: 0.9996 - val_acc: 0.6654\n",
            "Epoch 19/30\n",
            " - 86s - loss: 0.6652 - acc: 0.7670 - val_loss: 0.9873 - val_acc: 0.6720\n",
            "Epoch 20/30\n",
            " - 86s - loss: 0.6432 - acc: 0.7755 - val_loss: 1.0118 - val_acc: 0.6629\n",
            "Epoch 21/30\n",
            " - 86s - loss: 0.6265 - acc: 0.7818 - val_loss: 1.0273 - val_acc: 0.6619\n",
            "Epoch 22/30\n",
            " - 85s - loss: 0.5985 - acc: 0.7910 - val_loss: 1.0221 - val_acc: 0.6689\n",
            "Epoch 23/30\n",
            " - 85s - loss: 0.5881 - acc: 0.7937 - val_loss: 1.0638 - val_acc: 0.6553\n",
            "Epoch 24/30\n",
            " - 86s - loss: 0.5670 - acc: 0.8021 - val_loss: 1.0355 - val_acc: 0.6654\n",
            "Epoch 25/30\n",
            " - 85s - loss: 0.5475 - acc: 0.8093 - val_loss: 1.0414 - val_acc: 0.6664\n",
            "Epoch 26/30\n",
            " - 85s - loss: 0.5364 - acc: 0.8123 - val_loss: 1.0512 - val_acc: 0.6710\n",
            "Epoch 27/30\n",
            " - 85s - loss: 0.5170 - acc: 0.8186 - val_loss: 1.0468 - val_acc: 0.6662\n",
            "Epoch 28/30\n",
            " - 86s - loss: 0.5026 - acc: 0.8239 - val_loss: 1.0871 - val_acc: 0.6664\n",
            "Epoch 29/30\n",
            " - 86s - loss: 0.4896 - acc: 0.8284 - val_loss: 1.1183 - val_acc: 0.6567\n",
            "Epoch 30/30\n",
            " - 85s - loss: 0.4677 - acc: 0.8358 - val_loss: 1.1033 - val_acc: 0.6659\n",
            "CNN Error: 33.41%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}